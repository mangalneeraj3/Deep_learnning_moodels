{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP94kay4VO+g+YuTPOj66ze"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np"],"metadata":{"id":"SIWrYTPTxgVE"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fZ_TtlYAxES-"},"outputs":[],"source":["sentences = [\n","    \"king queen man woman\",\n","    \"king prince man\",\n","    \"queen princess woman\",\n","    \"man woman child\",\n","    \"king queen prince princess\",\n","    \"man king father\",\n","    \"woman queen mother\",\n","]\n"]},{"cell_type":"code","source":["\n","# tokenize\n","tokenized = [s.split() for s in sentences]\n","\n","# build vocabulary\n","vocab = sorted(set(word for sent in tokenized for word in sent))\n","word_to_id = {w: i for i, w in enumerate(vocab)}\n","id_to_word = {i: w for w, i in word_to_id.items()}\n","print(word_to_id.items())\n","print(id_to_word.items())\n","\n","V = len(vocab)\n","print(\"Vocabulary:\", vocab)\n","print(V)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uiodaVaWxIZ1","executionInfo":{"status":"ok","timestamp":1765704562564,"user_tz":-330,"elapsed":72,"user":{"displayName":"hindi hits","userId":"04012605303056951779"}},"outputId":"bfb042f2-7eb2-470c-c3e9-f0aba0f5abed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["dict_items([('child', 0), ('father', 1), ('king', 2), ('man', 3), ('mother', 4), ('prince', 5), ('princess', 6), ('queen', 7), ('woman', 8)])\n","dict_items([(0, 'child'), (1, 'father'), (2, 'king'), (3, 'man'), (4, 'mother'), (5, 'prince'), (6, 'princess'), (7, 'queen'), (8, 'woman')])\n","Vocabulary: ['child', 'father', 'king', 'man', 'mother', 'prince', 'princess', 'queen', 'woman']\n","9\n"]}]},{"cell_type":"code","source":["window_size = 1\n","pairs = []\n","\n","for sent in tokenized:\n","    for i, center in enumerate(sent):\n","        center_id = word_to_id[center]\n","        for j in range(max(0, i - window_size), min(len(sent), i + window_size + 1)):\n","            if i != j:\n","                context_id = word_to_id[sent[j]]\n","                pairs.append((center_id, context_id))\n","\n","print(\"Number of training pairs:\", len(pairs))\n","print(pairs)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"50qZ3rpS2MiE","executionInfo":{"status":"ok","timestamp":1765704506076,"user_tz":-330,"elapsed":65,"user":{"displayName":"hindi hits","userId":"04012605303056951779"}},"outputId":"d7fbe24c-5660-4754-8e24-2f066e62fa42"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of training pairs: 32\n","[(2, 7), (7, 2), (7, 3), (3, 7), (3, 8), (8, 3), (2, 5), (5, 2), (5, 3), (3, 5), (7, 6), (6, 7), (6, 8), (8, 6), (3, 8), (8, 3), (8, 0), (0, 8), (2, 7), (7, 2), (7, 5), (5, 7), (5, 6), (6, 5), (3, 2), (2, 3), (2, 1), (1, 2), (8, 7), (7, 8), (7, 4), (4, 7)]\n"]}]}]}